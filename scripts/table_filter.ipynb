{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "10193482",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-07-09T03:33:03.529036Z",
     "iopub.status.busy": "2025-07-09T03:33:03.528911Z",
     "iopub.status.idle": "2025-07-09T03:33:03.574010Z",
     "shell.execute_reply": "2025-07-09T03:33:03.573532Z"
    }
   },
   "outputs": [],
   "source": [
    "# pip install -r requirements.txt\n",
    "\n",
    "import os\n",
    "from pyspark.sql import SparkSession\n",
    "\n",
    "jar_dir = \"/home/bnguyen/Desktop/DE_project/scripts/jars\"\n",
    "os.environ[\"PYSPARK_SUBMIT_ARGS\"] = (\n",
    "    f\"--jars {jar_dir}/hadoop-common-3.3.6.jar,\"  # <-- Add this line\n",
    "    f\"{jar_dir}/hadoop-azure-3.3.6.jar,\"\n",
    "    f\"{jar_dir}/azure-storage-8.6.6.jar,\"\n",
    "    f\"{jar_dir}/jetty-client-9.4.43.v20210629.jar,\"\n",
    "    f\"{jar_dir}/jetty-http-9.4.43.v20210629.jar,\"\n",
    "    f\"{jar_dir}/jetty-io-9.4.43.v20210629.jar,\"\n",
    "    f\"{jar_dir}/jetty-util-9.4.43.v20210629.jar,\"\n",
    "    f\"{jar_dir}/jetty-util-ajax-9.4.43.v20210629.jar \"\n",
    "    \"pyspark-shell\"\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "43624bb5",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-07-09T03:33:03.575717Z",
     "iopub.status.busy": "2025-07-09T03:33:03.575569Z",
     "iopub.status.idle": "2025-07-09T03:33:17.365712Z",
     "shell.execute_reply": "2025-07-09T03:33:17.365097Z"
    }
   },
   "outputs": [],
   "source": [
    "# Init spark session\n",
    "spark = SparkSession.builder \\\n",
    "    .appName(\"Bronze to Silver: Table filter\") \\\n",
    "    .getOrCreate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "461e282f",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-07-09T03:33:17.367912Z",
     "iopub.status.busy": "2025-07-09T03:33:17.367655Z",
     "iopub.status.idle": "2025-07-09T03:33:17.526096Z",
     "shell.execute_reply": "2025-07-09T03:33:17.525670Z"
    }
   },
   "outputs": [],
   "source": [
    "# Bronze access key\n",
    "spark.conf.set(\n",
    "    \"fs.azure.account.key.mybronze.dfs.core.windows.net\",\n",
    "    \"c5etqTidViezB/4ukOAALy23HeMBsJJ8g+2nFaIdbC7E9PhLw0y2YIA1ItjutpqS1/8Ga8fw40mR+ASt2T+/sw==\"\n",
    ")\n",
    "\n",
    "# Silver access key\n",
    "spark.conf.set(\n",
    "    \"fs.azure.account.key.mysilver.dfs.core.windows.net\",\n",
    "    \"bAthp0pVBfqEtyCvJElSX7MeI7ejSLa6cjuPoMz0Gg/69uzEW01y4URMDXsdFCrkpc9M54cDHnXs+AStj1gExQ==\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "af3e3497",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-07-09T03:33:17.527672Z",
     "iopub.status.busy": "2025-07-09T03:33:17.527526Z",
     "iopub.status.idle": "2025-07-09T03:33:17.530075Z",
     "shell.execute_reply": "2025-07-09T03:33:17.529668Z"
    }
   },
   "outputs": [],
   "source": [
    "# Define storage account \n",
    "storage_account_bronze = \"mybronze\"\n",
    "bronze_container = \"bronze\"\n",
    "storage_account_silver = \"mysilver\"\n",
    "silver_container = \"silver\"\n",
    "\n",
    "tables = [\"Customers\", \"Products\", \n",
    "          \"Sellers\", \"Orders\", \n",
    "          \"OrderItems\",\"ProductCategories\",\n",
    "          \"OrderStatus\",\"Reasons\", \"Payments\"]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "88a1e2fe",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "25/07/17 12:05:16 WARN GarbageCollectionMetrics: To enable non-built-in garbage collector(s) List(G1 Concurrent GC), users should configure it(them) to spark.eventLog.gcMetrics.youngGenerationGarbageCollectors or spark.eventLog.gcMetrics.oldGenerationGarbageCollectors\n"
     ]
    }
   ],
   "source": [
    "bronze_path = f\"abfss://{bronze_container}@{storage_account_bronze}.dfs.core.windows.net/Customers\"\n",
    "df = spark.read.parquet(bronze_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "d86dc7f4",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+----------------+--------------------+--------------------+-------------------+-------------------+\n",
      "|CustomerID|            Name|               Email|         PhoneNumber|          CreatedAt|          UpdatedAt|\n",
      "+----------+----------------+--------------------+--------------------+-------------------+-------------------+\n",
      "|         1|    Charles Park| tmiller@example.com|  793-701-5921x92794|2024-02-26 17:56:18|2024-11-20 20:17:14|\n",
      "|         2| Michael Estrada|  rbrown@example.org|          6953312991|2023-12-09 16:51:08|2025-06-28 11:45:07|\n",
      "|         3|  Gail Wilkerson|graybrittany@exam...|        550.265.9882|2024-02-09 17:10:59|2025-05-26 07:26:49|\n",
      "|         4| Alexandra Moyer|  mark96@example.org|     +1-978-296-4775|2024-11-26 14:08:20|2024-09-27 03:46:33|\n",
      "|         5|   Natasha Perry| katie74@example.com|        457.834.5540|2024-11-17 05:40:49|2024-07-17 05:36:49|\n",
      "|         6|Rachel Wilkerson|  rsmith@example.com|        846.591.5494|2025-05-08 17:12:32|2025-06-21 09:52:58|\n",
      "|         7|   Debbie Knight|carolyn59@example...|     +1-286-257-6420|2025-07-04 11:16:29|2024-09-04 08:14:22|\n",
      "|         8|   Nancy Herring|   gking@example.com|  (753)364-3823x1152|2023-12-05 10:52:15|2024-11-02 09:18:16|\n",
      "|         9|    Aaron Potter|ramseymiranda@exa...|  (616)332-0263x9430|2025-05-20 09:50:15|2024-09-26 01:59:04|\n",
      "|        10|        Chris Li|lowerymiguel@exam...|001-229-458-8691x419|2023-08-15 22:56:00|2025-03-20 16:55:27|\n",
      "|        11|  Rebecca Murray| joann00@example.net|  317.814.7648x48701|2025-06-14 01:27:20|2024-10-09 11:53:43|\n",
      "|        12|  Ronald Johnson|barryreeves@examp...|+1-986-426-6737x6620|2023-12-09 05:35:56|2025-05-30 02:57:32|\n",
      "|        13|        Amy Lane|   wgray@example.net|          3592759910|2023-10-15 20:18:40|2025-06-18 02:35:38|\n",
      "|        14| Anthony Wheeler|joshua69@example.com|    501.998.3758x009|2024-07-04 12:45:55|2025-01-08 17:34:02|\n",
      "|        15|Jessica Guerrero|andrew22@example.org|       (815)447-5016|2023-12-26 00:45:28|2024-07-18 17:41:34|\n",
      "|        16|        Luke Key|xcastillo@example...| (483)284-7838x85857|2024-11-18 12:03:36|2025-05-21 16:01:37|\n",
      "|        17|    Adam Russell|wandrews@example.com|    001-440-703-6193|2024-06-11 13:22:09|2024-12-15 16:07:05|\n",
      "|        18|  Donna Williams|andrewhenry@examp...|          2214294127|2024-11-17 23:32:11|2024-08-27 15:36:56|\n",
      "|        19| Candice Chan MD|talvarez@example.net|   486-462-1079x1709|2025-04-20 08:11:13|2024-08-17 22:03:02|\n",
      "|        20|     Kyle Snyder|  sara51@example.org|    001-780-739-2064|2025-06-11 14:11:16|2024-08-27 10:12:20|\n",
      "+----------+----------------+--------------------+--------------------+-------------------+-------------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# https://mybronze.blob.core.windows.net/bronze/Customers/ingestion_timestamp=2025-07-16%2009%253A35%253A10.005/\n",
    "df.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "8a17c52a",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-07-09T03:33:17.531511Z",
     "iopub.status.busy": "2025-07-09T03:33:17.531356Z",
     "iopub.status.idle": "2025-07-09T03:34:50.038832Z",
     "shell.execute_reply": "2025-07-09T03:34:50.038430Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing Customers...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "25/07/09 12:39:32 WARN MetricsConfig: Cannot locate configuration: tried hadoop-metrics2-azure-file-system.properties,hadoop-metrics2.properties\n",
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Written to abfss://silver@mysilver.dfs.core.windows.net/Customers\n",
      "Processing Products...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Written to abfss://silver@mysilver.dfs.core.windows.net/Products\n",
      "Processing Sellers...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Written to abfss://silver@mysilver.dfs.core.windows.net/Sellers\n",
      "Processing Orders...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Written to abfss://silver@mysilver.dfs.core.windows.net/Orders\n",
      "Processing OrderItems...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Written to abfss://silver@mysilver.dfs.core.windows.net/OrderItems\n",
      "Processing ProductCategories...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Written to abfss://silver@mysilver.dfs.core.windows.net/ProductCategories\n",
      "Processing OrderStatus...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Written to abfss://silver@mysilver.dfs.core.windows.net/OrderStatus\n",
      "Processing Reasons...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Written to abfss://silver@mysilver.dfs.core.windows.net/Reasons\n",
      "Processing Payments...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Written to abfss://silver@mysilver.dfs.core.windows.net/Payments\n"
     ]
    }
   ],
   "source": [
    "for table in tables:\n",
    "    bronze_path = f\"wasbs://{bronze_container}@{storage_account_bronze}.blob.core.windows.net/{table}\"\n",
    "    silver_path = f\"abfss://{silver_container}@{storage_account_silver}.dfs.core.windows.net/{table}\"\n",
    "\n",
    "    print(f\"Processing {table}...\")\n",
    "    \n",
    "    df = spark.read.parquet(bronze_path)\n",
    "    df.write.mode(\"overwrite\").parquet(silver_path)\n",
    "\n",
    "    print(f\"Written to {silver_path}\")\n",
    "\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "6fdba4b8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing Customers...\n",
      "  ðŸ“Š Found 7000 records in bronze\n",
      "  ðŸ“‹ Sample data:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+---------------+--------------------+------------------+-------------------+-------------------+\n",
      "|CustomerID|           Name|               Email|       PhoneNumber|          CreatedAt|          UpdatedAt|\n",
      "+----------+---------------+--------------------+------------------+-------------------+-------------------+\n",
      "|         1|   Charles Park| tmiller@example.com|793-701-5921x92794|2024-02-26 17:56:18|2024-11-20 20:17:14|\n",
      "|         2|Michael Estrada|  rbrown@example.org|        6953312991|2023-12-09 16:51:08|2025-06-28 11:45:07|\n",
      "|         3| Gail Wilkerson|graybrittany@exam...|      550.265.9882|2024-02-09 17:10:59|2025-05-26 07:26:49|\n",
      "|         4|Alexandra Moyer|  mark96@example.org|   +1-978-296-4775|2024-11-26 14:08:20|2024-09-27 03:46:33|\n",
      "|         5|  Natasha Perry| katie74@example.com|      457.834.5540|2024-11-17 05:40:49|2024-07-17 05:36:49|\n",
      "+----------+---------------+--------------------+------------------+-------------------+-------------------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  âœ“ Successfully copied 7000 records to bronze-final\n",
      "  ðŸ“ Destination: abfss://bronze-final@mybronze.dfs.core.windows.net/Customers\n",
      "\n",
      "Customers table is ready for continuous CDC merging!\n"
     ]
    }
   ],
   "source": [
    "# Copy content for just the Customers table\n",
    "# This will create the initial baseline for the Customers table in bronze-final\n",
    "\n",
    "# Configure paths\n",
    "table = \"Customers\"\n",
    "bronze_path = f\"abfss://{bronze_container}@{storage_account_bronze}.dfs.core.windows.net/{table}\"\n",
    "bronze_final_path = f\"abfss://bronze-final@{storage_account_bronze}.dfs.core.windows.net/{table}\"\n",
    "\n",
    "print(f\"Processing {table}...\")\n",
    "\n",
    "try:\n",
    "    # Read from bronze\n",
    "    df = spark.read.parquet(bronze_path)\n",
    "    record_count = df.count()\n",
    "    \n",
    "    print(f\"  ðŸ“Š Found {record_count} records in bronze\")\n",
    "    \n",
    "    # Show sample data\n",
    "    print(\"  ðŸ“‹ Sample data:\")\n",
    "    df.show(5)\n",
    "    \n",
    "    # Write to bronze-final with overwrite mode\n",
    "    df.write.mode(\"overwrite\").parquet(bronze_final_path)\n",
    "    \n",
    "    print(f\"  âœ“ Successfully copied {record_count} records to bronze-final\")\n",
    "    print(f\"  ðŸ“ Destination: {bronze_final_path}\")\n",
    "    \n",
    "except Exception as e:\n",
    "    print(f\"  âœ— Error processing {table}: {e}\")\n",
    "\n",
    "print(f\"\\n{table} table is ready for continuous CDC merging!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c1f715a0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing Customers...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  âœ“ Copied 7000 records to bronze-final\n",
      "Processing Products...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  âœ“ Copied 6000 records to bronze-final\n",
      "Processing Sellers...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  âœ“ Copied 4000 records to bronze-final\n",
      "Processing Orders...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  âœ“ Copied 100000 records to bronze-final\n",
      "Processing OrderItems...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  âœ“ Copied 300756 records to bronze-final\n",
      "Processing ProductCategories...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  âœ“ Copied 10 records to bronze-final\n",
      "Processing OrderStatus...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  âœ“ Copied 5 records to bronze-final\n",
      "Processing Reasons...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  âœ“ Copied 4931 records to bronze-final\n",
      "Processing Payments...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  âœ“ Copied 80200 records to bronze-final\n",
      "\n",
      "Initial merge completed!\n",
      "Bronze-final containers are ready for continuous CDC merging.\n"
     ]
    }
   ],
   "source": [
    "# Initial merge: Copy bronze data to bronze-final and silver-final\n",
    "# This creates the baseline for the continuous merge process\n",
    "\n",
    "# Configure bronze-final storage\n",
    "storage_account_bronze_final = \"mybronze\"\n",
    "storage_account_silver_final = \"mysilver\"\n",
    "bronze_final_container = \"bronze-final\"\n",
    "silver_final_container = \"silver-final\"\n",
    "\n",
    "# Set access key for bronze-final (same as bronze)\n",
    "spark.conf.set(\n",
    "    \"fs.azure.account.key.mybronze.dfs.core.windows.net\",\n",
    "    \"c5etqTidViezB/4ukOAALy23HeMBsJJ8g+2nFaIdbC7E9PhLw0y2YIA1ItjutpqS1/8Ga8fw40mR+ASt2T+/sw==\"\n",
    ")\n",
    "\n",
    "spark.conf.set(\n",
    "        \"fs.azure.account.key.mysilver.dfs.core.windows.net\",\n",
    "        \"bAthp0pVBfqEtyCvJElSX7MeI7ejSLa6cjuPoMz0Gg/69uzEW01y4URMDXsdFCrkpc9M54cDHnXs+AStj1gExQ==\"\n",
    "    )\n",
    "\n",
    "for table in tables:\n",
    "    bronze_path = f\"abfss://{bronze_container}@{storage_account_bronze}.dfs.core.windows.net/{table}\"\n",
    "    bronze_final_path = f\"abfss://{bronze_final_container}@{storage_account_bronze_final}.dfs.core.windows.net/{table}\"\n",
    "    silver_final_path = f\"abfss://{silver_final_container}@{storage_account_silver_final}.dfs.core.windows.net/{table}\"\n",
    "\n",
    "    print(f\"Processing {table}...\")\n",
    "    \n",
    "    try:\n",
    "        # Read from bronze\n",
    "        df = spark.read.parquet(bronze_path)\n",
    "        record_count = df.count()\n",
    "        \n",
    "        # Write with overwrite mode\n",
    "        df.write.mode(\"overwrite\").parquet(bronze_final_path)\n",
    "        df.write.mode(\"overwrite\").parquet(silver_final_path)\n",
    "        \n",
    "        print(f\"  âœ“ Copied {record_count} records\")\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"  âœ— Error processing {table}: {e}\")\n",
    "\n",
    "print(\"\\nInitial merge completed!\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
